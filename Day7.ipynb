{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNEsDXohjq9K4lhNxykvLHH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive/\", force_remount=True)"],"metadata":{"id":"5Ae6zHl5wQ8J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorboardX\n","!pip install pytorchcv\n","\n","import numpy as np\n","import torch\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","import torch.cuda\n","import torch.multiprocessing\n","import warnings\n","import torch.nn as nn\n","from tensorboardX import SummaryWriter\n","import os\n","from pytorchcv.model_provider import get_model as ptcv_get_model\n","from torch.utils.data import Dataset\n","from imgaug import augmenters as iaa\n","from PIL import Image\n","import dlib\n","import cv2\n","from collections import OrderedDict\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as image\n","\n","warnings.filterwarnings(action='ignore')\n","\n","torch.backends.cudnn.benchmark = True\n","\n","step = 0\n","Acc_val_max = 0.0"],"metadata":{"id":"BgyHeV5uwSEy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imagenet_stats = {'mean': [0.485, 0.456, 0.406],\n","                    'std': [0.229, 0.224, 0.225]}\n","\n","\n","def datapair_generator(arg, data, data_age, lb_list, up_list):\n","    ref_list = []\n","    test_list = []\n","\n","    data_age_max = data_age.max()\n","    data_age_min = data_age.min()\n","\n","    tau_2 = arg.tau + 5\n","\n","    lb_list_hard, up_list_hard = get_bounds(data_age_min, data_age_max, tau=tau_2)\n","\n","    invalid_age = np.setdiff1d(np.arange(int(data_age_max) + 1), np.unique(data_age))\n","\n","    for i, ref_age in enumerate(data_age):\n","        ref_age -= 18\n","        flag = np.random.rand()\n","\n","        if flag < 0.1:\n","            start, end = data_age_min, lb_list_hard[ref_age]\n","        elif 0.1 <= flag < 0.3:\n","            start, end = lb_list_hard[ref_age], lb_list[ref_age]\n","        elif 0.3 <= flag < 0.7:\n","            start, end = lb_list[ref_age], up_list[ref_age]\n","        elif 0.7 <= flag < 0.9:\n","            start, end = up_list[ref_age], up_list_hard[ref_age]\n","        elif flag >= 0.9:\n","            start, end = up_list_hard[ref_age], data_age_max\n","\n","        candidate_age = np.setdiff1d(np.arange(int(start), int(end) + 1), invalid_age)\n","        test_age = np.random.choice(candidate_age, 1)\n","\n","        idx_test = np.where(data_age == test_age[0])[0]\n","\n","        ref_list.append(i)\n","        test_list.append(np.random.choice(idx_test, 1)[0].tolist())\n","\n","    ref_list = data[np.array(ref_list)]\n","    test_list = data[np.array(test_list)]\n","\n","    return ref_list, test_list\n","\n","\n","def ImgAugTransform(img):\n","    aug = iaa.Sequential([\n","        iaa.CropToFixedSize(width=224, height=224),\n","        iaa.Fliplr(0.5),\n","    ])\n","\n","    img = np.array(img)\n","    img = aug(image=img)\n","    return img\n","\n","\n","def ImgAugTransform_Test(img):\n","    aug = iaa.Sequential([\n","        iaa.CropToFixedSize(width=224, height=224, position=\"center\")\n","    ])\n","\n","    img = np.array(img)\n","    img = aug(image=img)\n","    return img\n"],"metadata":{"id":"7BZd_WclwTNt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AgeDataLoader(Dataset):\n","    def __init__(self, arg):\n","\n","        self.path = arg.data_path\n","        with open(os.path.join(arg.data_path, \"train_image.txt\"), \"r\") as fp:\n","            self.data = [d.splitlines()[0] for d in fp.readlines()]\n","\n","        self.age_data = [int(d.split(\"/\")[0]) for d in self.data]\n","        self.data, self.age_data = np.array(self.data), np.array(self.age_data)\n","        lb_list, up_list = get_bounds(self.age_data.min(), self.age_data.max(), tau=arg.tau)\n","        ref_list, test_list = datapair_generator(arg, self.data, self.age_data, lb_list, up_list)\n","\n","        self.reg_img_list = ref_list\n","        self.test_img_list = test_list\n","        self.label_list = []\n","\n","        for i in range(len(ref_list)):\n","\n","            ref_age, test_age = int(self.reg_img_list[i].split(\"/\")[0]), int(self.test_img_list[i].split(\"/\")[0])\n","\n","            if test_age < lb_list[ref_age - 18]:\n","                class_name = 0\n","\n","            elif test_age > up_list[ref_age - 18]:\n","                class_name = 2\n","\n","            else:\n","                class_name = 1\n","\n","            self.label_list.append(class_name)\n","\n","    def __len__(self):\n","        return len(self.label_list)\n","\n","    def __getitem__(self, idx):\n","        ref_img_path = os.path.join(self.path, self.reg_img_list[idx])\n","        test_img_path = os.path.join(self.path, self.test_img_list[idx])\n","        label = self.label_list[idx]\n","\n","        ref_img = Image.open(str(ref_img_path))\n","        ref_img = ref_img.resize((224, 224))\n","\n","        test_img = Image.open(str(test_img_path))\n","        test_img = test_img.resize((224, 224))\n","\n","        ref_img = ImgAugTransform(ref_img).astype(np.float32) / 255.\n","        test_img = ImgAugTransform(test_img).astype(np.float32) / 255.\n","\n","        ref_img = torch.from_numpy(np.transpose(ref_img, (2, 0, 1)))\n","        test_img = torch.from_numpy(np.transpose(test_img, (2, 0, 1)))\n","\n","        dtype = ref_img.dtype\n","        mean = torch.as_tensor(imagenet_stats['mean'], dtype=dtype, device=ref_img.device)\n","        std = torch.as_tensor(imagenet_stats['std'], dtype=dtype, device=ref_img.device)\n","        ref_img.sub_(mean[:, None, None]).div_(std[:, None, None])\n","        test_img.sub_(mean[:, None, None]).div_(std[:, None, None])\n","\n","        return ref_img, test_img, label"],"metadata":{"id":"6o4HKR9DwUWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Model_BN_VGG16(torch.nn.Module):\n","    def __init__(self):\n","        super(Model_BN_VGG16, self).__init__()\n","        self.encoder = ptcv_get_model(\"bn_vgg16\", pretrained=True).features\n","        self.comparator = Comparator_v1(1024, 512)\n","        self.avg_pool = nn.AvgPool2d(kernel_size=7)\n","\n","    def forward_siamese(self, x):\n","        x = self.encoder.stage1(x)\n","        x = self.encoder.stage2(x)\n","        x = self.encoder.stage3(x)\n","        x = self.encoder.stage4(x)\n","        x = self.encoder.stage5(x)\n","        x = self.avg_pool(x)\n","\n","        return x.squeeze()\n","\n","    def forward(self, phase, **kwargs):\n","        if phase == 'train':\n","            x_1, x_2 = kwargs['x_1'], kwargs['x_2']\n","            x_1 = self.forward_siamese(x_1)\n","            x_2 = self.forward_siamese(x_2)\n","\n","            x = torch.cat([x_1, x_2], dim=1)\n","\n","            output = self.comparator(x)\n","\n","            return output\n","\n","        elif phase == 'test':\n","            x_1, x_2 = kwargs['ref'], kwargs['test']\n","            x = torch.cat([x_1, x_2], dim=1)\n","\n","            output = self.comparator(x)\n","\n","            return output\n","\n","        elif phase == 'extraction':\n","            x = kwargs['x']\n","            x = self.forward_siamese(x)\n","\n","            return x\n","\n","\n","class Comparator_v1(torch.nn.Sequential):\n","    def __init__(self, input_channel, output_channel):\n","        super(Comparator_v1, self).__init__()\n","        self.fcA = nn.Linear(input_channel, output_channel)\n","        self.leakyreluA = nn.ReLU(inplace=True)\n","        self.fcB = nn.Linear(output_channel, output_channel)\n","        self.leakyreluB = nn.ReLU(inplace=True)\n","        self.dropout = nn.Dropout(p=0.8)\n","        self.fcC = nn.Linear(output_channel, 3)\n","\n","    def forward(self, x):\n","        x = self.fcA(x)\n","        x = self.leakyreluA(x)\n","        x = self.fcB(x)\n","        x = self.leakyreluB(x)\n","        x = self.dropout(x)\n","        x = self.fcC(x)\n","\n","        return x\n","\n","\n","def create_model():\n","    # Create model\n","    print('Get BN_Vgg16')\n","    model = Model_BN_VGG16().cuda()\n","\n","    return model"],"metadata":{"id":"nD8q7XIMwVZn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_bounds(age_min, age_max, tau=3):\n","    lb_list = []\n","    up_list = []\n","\n","    for age_tmp in range(18, age_max + 1):\n","        lb = max(age_tmp - tau, age_min)\n","        up = min(age_tmp + tau, age_max)\n","\n","        lb_list.append(lb)\n","        up_list.append(up)\n","\n","    return lb_list, up_list\n","\n","def train(arg):\n","    global step, Acc_val_max\n","    os.makedirs(arg.test_model_path, exist_ok=True)\n","\n","    device = torch.device(\"cuda:%s\" % 0 if torch.cuda.is_available() else \"cpu\")\n","    print(device)\n","\n","    model = create_model()\n","    model.to(device)\n","\n","    for param in model.comparator.parameters():\n","        param.requires_grad = False\n","\n","    optimizer = torch.optim.Adam(list(model.parameters()), lr=arg.lr)\n","\n","    if arg.pretrained:\n","        initial_model = os.path.join(arg.pretrained_model_path)\n","        checkpoint = torch.load(initial_model, map_location=device)\n","        model_dict = model.state_dict()\n","\n","        from collections import OrderedDict\n","        new_model_state_dict = OrderedDict()\n","        for k, v in model_dict.items():\n","            if k in checkpoint['model_state_dict'].keys():\n","                new_model_state_dict[k] = checkpoint['model_state_dict'][k]\n","                print(f'Loaded\\t{k}')\n","            else:\n","                new_model_state_dict[k] = v\n","                print(f'Not Loaded\\t{k}')\n","\n","        model.load_state_dict(new_model_state_dict)\n","\n","        optimizer_dict = optimizer.state_dict()\n","        optimizer_dict.update(checkpoint['optimizer_state_dict'])\n","        optimizer.load_state_dict(optimizer_dict)\n","\n","        print(\"=> loaded checkpoint '{}'\".format(initial_model))\n","\n","    criterion = nn.CrossEntropyLoss()\n","    criterion.to(device)\n","    writer = SummaryWriter()\n","\n","    model.train()\n","\n","    best_acc = 0.0\n","    for epoch in range(0, arg.epoch):\n","        local_step = 0\n","        running_loss = 0.0\n","        Acc_train = 0.0\n","\n","        Train = AgeDataLoader(arg)\n","        dataloader_train = DataLoader(Train, batch_size=arg.train_batch_size, shuffle=True, num_workers=4)\n","\n","        for i, data in enumerate(tqdm(dataloader_train, desc=\"Train\")):\n","            ref, test, labels = data[0], data[1], data[2]\n","            labels = labels.view(1, -1)[0]\n","            ref, test, labels = ref.to(device), test.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            with torch.set_grad_enabled(mode=True):\n","                outputs = model('train', x_1=ref, x_2=test)\n","                outputs = outputs.squeeze()\n","                loss = criterion(outputs, labels).to(device)\n","\n","                loss.backward()\n","                optimizer.step()\n","\n","            running_loss += loss.item() * arg.train_batch_size\n","            Acc_train += (torch.argmax(outputs, 1) == labels).float().sum()\n","\n","            writer.add_scalar('train/loss', loss.item(), global_step=step)\n","            writer.add_scalar('train/acc',\n","                              float((torch.argmax(outputs, 1) == labels).float().sum() / arg.train_batch_size),\n","                              global_step=step)\n","\n","            step += 1\n","            local_step += 1\n","\n","        print('Train')\n","        print('epoch : %d, loss: %.4f, acc: %.4f' % (epoch + 1, running_loss / len(Train), Acc_train / len(Train)))\n","\n","        acc = Acc_train / len(Train)\n","\n","        if acc > best_acc:\n","          best_acc = acc\n","          torch.save({\n","              'epoch': epoch,\n","              'model_state_dict': model.state_dict(),\n","              'optimizer_state_dict': optimizer.state_dict(),\n","              'loss': running_loss\n","          }, os.path.join(arg.test_model_path, 'Epoch_{:04d}.pth'.format(epoch + 1)))\n","    print('Finished Training')\n"],"metadata":{"id":"QYnOfUEFwWLT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import easydict\n","\n","dataset_path = \"/content/gdrive/MyDrive/2024_MCL_Internship/AgeEstimation/dataset/AFAD-Lite\"\n","ckpt_path = \"/content/gdrive/MyDrive/2024_MCL_Internship/AgeEstimation/checkpoints_day7\"\n","if not os.path.exists(ckpt_path): os.mkdir(ckpt_path)\n","\n","train_arg = easydict.EasyDict({\n","    \"tau\": 3,\n","    \"lr\" : 1e-4,\n","    \"train_batch_size\": 18,\n","    \"test_batch_size\": 1,\n","    \"epoch\": 100,\n","    \"pretrained\": False,\n","    \"pretrained_model_path\": None,\n","    \"test_model_path\": ckpt_path,\n","    \"data_path\": dataset_path\n","})\n","\n","train(train_arg)"],"metadata":{"id":"iix9yWN5wcLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SingleImage(Dataset):\n","    def __init__(self, arg, data, img_size=256):\n","\n","        self.data = np.array(data)\n","        self.img_size = img_size\n","\n","        self.img = []\n","\n","        for da in self.data:\n","            img_path = os.path.join(arg.data_path, da)\n","            self.img.append(str(img_path))\n","\n","    def __len__(self):\n","        return len(self.img)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img[idx]\n","\n","        img = Image.open(str(img_path))\n","        img = img.resize((self.img_size, self.img_size))\n","        img = ImgAugTransform_Test(img).astype(np.float32) / 255.\n","\n","        img = torch.from_numpy(np.transpose(img, (2, 0, 1)))\n","\n","        dtype = img.dtype\n","        mean = torch.as_tensor(imagenet_stats['mean'], dtype=dtype, device=img.device)\n","        std = torch.as_tensor(imagenet_stats['std'], dtype=dtype, device=img.device)\n","        img.sub_(mean[:, None, None]).div_(std[:, None, None])\n","\n","        return img\n","\n","\n","class SingleImage_val(Dataset):\n","    def __init__(self, arg, data, img_size=256):\n","        self.img_size = img_size\n","\n","        self.img = [str(data[0])]\n","\n","    def __len__(self):\n","        return len(self.img)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img[idx]\n","\n","        img = Image.open(str(img_path))\n","        img = img.resize((self.img_size, self.img_size))\n","        img = ImgAugTransform_Test(img).astype(np.float32) / 255.\n","\n","        img = torch.from_numpy(np.transpose(img, (2, 0, 1)))\n","\n","        dtype = img.dtype\n","        mean = torch.as_tensor(imagenet_stats['mean'], dtype=dtype, device=img.device)\n","        std = torch.as_tensor(imagenet_stats['std'], dtype=dtype, device=img.device)\n","        img.sub_(mean[:, None, None]).div_(std[:, None, None])\n","\n","        return img\n","\n","\n","def feature_extraction(arg, train_data, test_data, model, device):\n","    features = {'train': [], 'test': []}\n","\n","    Images_train = SingleImage(arg, train_data)\n","    dataloader_Images_train = DataLoader(Images_train, batch_size=100, shuffle=False, num_workers=4)\n","\n","    if not type(test_data) == list:\n","        Images_test = SingleImage(arg, test_data)\n","        dataloader_Images_test = DataLoader(Images_test, batch_size=100, shuffle=False, num_workers=4)\n","    else:\n","        Images_test = SingleImage_val(arg, test_data)\n","        dataloader_Images_test = DataLoader(Images_test, batch_size=100, shuffle=False, num_workers=4)\n","\n","    with torch.no_grad():\n","        for i, data in enumerate(tqdm(dataloader_Images_train, desc='Extract Train Data Features')):\n","            inputs = data\n","            inputs = inputs.to(device)\n","\n","            outputs = torch.squeeze(model('extraction', x=inputs))\n","            outputs_numpy = outputs.cpu().detach().numpy().reshape(-1, 512)\n","            features['train'].extend(outputs_numpy)\n","\n","        for i, data in enumerate(tqdm(dataloader_Images_test, desc='Extract Test Data Features')):\n","            inputs = data\n","            inputs = inputs.to(device)\n","\n","            outputs = torch.squeeze(model('extraction', x=inputs))\n","            outputs_numpy = outputs.cpu().detach().numpy().reshape(-1, 512)\n","            features['test'].extend(outputs_numpy)\n","\n","    features = {'train': np.array(features['train']), 'test': np.array(features['test'])}\n","\n","    return features"],"metadata":{"id":"bUUOIEbVwaSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def select_reference_randomly(train_data, train_data_age, limit=20):\n","    # ref vector\n","    refer_idx = []\n","    refer_age = []\n","    train_data_age = np.array(train_data_age)\n","    for i in range(90):\n","        # ref_image = train_data.loc[train_data['age'] == i]\n","        ref_image = train_data[train_data_age == i]\n","        if len(ref_image) >= limit:\n","            gap = int(len(ref_image) / min(len(ref_image), limit))\n","            idx = np.where(train_data_age == i)[0][np.arange(0, min(len(ref_image), gap * limit), gap)].tolist()\n","            refer_idx.append(idx)\n","            refer_age.append([i] * len(idx))\n","        elif 0 < len(ref_image) < limit:\n","            gap = int(len(ref_image) / min(len(ref_image), limit))\n","            idx = np.where(train_data_age == i)[0][np.arange(0, min(len(ref_image), gap * limit), gap)].tolist()\n","\n","            need = limit - len(idx)\n","            idx_additional = np.random.choice(idx, need, replace=True).tolist()\n","            idx = idx + idx_additional\n","            refer_idx.append(idx)\n","            refer_age.append([i] * len(idx))\n","        else:\n","            refer_idx.append([])\n","            refer_age.append([])\n","\n","    return refer_idx, refer_age"],"metadata":{"id":"BV_pnjkmwbrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_age_random(arg, test_data, epoch):\n","    device = torch.device(\"cuda:%s\" % 0 if torch.cuda.is_available() else \"cpu\")\n","    print(device)\n","\n","    model = create_model()\n","    model.to(device)\n","\n","    for param in model.comparator.parameters():\n","        param.requires_grad = False\n","\n","    optimizer = torch.optim.Adam(list(model.parameters()), lr=arg.lr)\n","\n","    # initial_model = os.path.join(os.path.join(arg.test_model_path, 'Epoch_{:04d}.pth'.format(epoch)))\n","    initial_model = \"/content/gdrive/MyDrive/2024_MCL_Internship/AgeEstimation/checkpoints_day7/Epoch_0100.pth\"\n","    print(initial_model)\n","\n","    checkpoint = torch.load(initial_model, map_location=device)\n","    model_dict = model.state_dict()\n","\n","    from collections import OrderedDict\n","    new_model_state_dict = OrderedDict()\n","    for k, v in model_dict.items():\n","        if k in checkpoint['model_state_dict'].keys():\n","            new_model_state_dict[k] = checkpoint['model_state_dict'][k]\n","            # print(f'Loaded\\t{k}')\n","        else:\n","            new_model_state_dict[k] = v\n","            # print(f'Not Loaded\\t{k}')\n","\n","    model.load_state_dict(new_model_state_dict)\n","\n","    optimizer_dict = optimizer.state_dict()\n","    optimizer_dict.update(checkpoint['optimizer_state_dict'])\n","    optimizer.load_state_dict(optimizer_dict)\n","\n","    print(\"=> loaded checkpoint '{}'\".format(initial_model))\n","\n","    model.eval()\n","\n","    with open(os.path.join(arg.data_path, \"train_image.txt\"), \"r\") as fp:\n","        train_data = np.array([d.splitlines()[0] for d in fp.readlines()])\n","\n","    test_data = preprocess(test_data)\n","\n","    age_data = np.array([int(d.split(\"/\")[0]) for d in train_data])\n","\n","    features = feature_extraction(arg, train_data, test_data, model, device)\n","    refer_idx, refer_age = select_reference_randomly(train_data, age_data, limit=5)\n","    refer_idx, refer_age = sum(refer_idx, []), sum(refer_age, [])\n","\n","    lb, ub = get_bounds(age_data.min(), age_data.max(), arg.tau)\n","\n","    predicted_age = []\n","\n","    fig = plt.figure()\n","    ax0 = fig.add_subplot(3, 3, 1)\n","    ax0.get_xaxis().set_visible(False)\n","    ax0.get_yaxis().set_visible(False)\n","    ax1 = fig.add_subplot(3, 3, 2)\n","    ax1.get_xaxis().set_visible(False)\n","    ax1.get_yaxis().set_visible(False)\n","    ax2 = fig.add_subplot(3, 3, 4)\n","    ax2.get_xaxis().set_visible(False)\n","    ax2.get_yaxis().set_visible(False)\n","    ax3 = fig.add_subplot(3, 3, 5)\n","    ax3.get_xaxis().set_visible(False)\n","    ax3.get_yaxis().set_visible(False)\n","    ax4 = fig.add_subplot(3, 3, 6)\n","    ax4.get_xaxis().set_visible(False)\n","    ax4.get_yaxis().set_visible(False)\n","    ax5 = fig.add_subplot(3, 3, 8)\n","    ax5.get_xaxis().set_visible(False)\n","    ax5.get_yaxis().set_visible(False)\n","    ax6 = fig.add_subplot(3, 3, 9)\n","    ax6.get_xaxis().set_visible(False)\n","    ax6.get_yaxis().set_visible(False)\n","    less = False\n","    sim = False\n","    larg = False\n","\n","    with torch.no_grad():\n","        for i in tqdm(range(len(test_data)), \"Test\"):\n","            vote = np.zeros(shape=23, dtype=np.int)\n","\n","            test_duplicate = [i] * len(refer_idx)\n","            ref_features, test_feature = np.array(features['train'][refer_idx]), np.array(\n","                features['test'][test_duplicate])\n","            ref_features, test_feature = torch.as_tensor(ref_features, dtype=torch.float32).to(device), torch.as_tensor(\n","                test_feature, dtype=torch.float32).to(device)\n","            outputs = model('test', ref=ref_features, test=test_feature).argmax(dim=1).squeeze().cpu().detach().numpy()\n","\n","            for j in range(len(refer_age)):\n","                if outputs[j] == 0:\n","                    if not less:\n","                        img = image.imread(os.path.join(arg.data_path, train_data[j]))\n","                        ax0.imshow(img)\n","                        less = True\n","                    else:\n","                        img = image.imread(os.path.join(arg.data_path, train_data[j]))\n","                        ax1.imshow(img)\n","                    vote[:int(lb[refer_age[j] - 18] - 18)] += 1\n","                elif outputs[j] == 2:\n","                    if not larg:\n","                        img = image.imread(os.path.join(arg.data_path, train_data[j]))\n","                        ax5.imshow(img)\n","                        larg = True\n","                    else:\n","                        img = image.imread(os.path.join(arg.data_path, train_data[j]))\n","                        ax6.imshow(img)\n","                    vote[int(ub[refer_age[j] - 18] + 1 - 18):] += 1\n","                else:\n","                    if not sim:\n","                        img = image.imread(os.path.join(arg.data_path, train_data[j]))\n","                        ax2.imshow(img)\n","                        sim = True\n","                    else:\n","                        img = image.imread(os.path.join(arg.data_path, train_data[j]))\n","                        ax4.imshow(img)\n","                    vote[int(lb[refer_age[j] - 18] - 18):int(ub[refer_age[j] - 18] + 1 - 18)] += 1\n","\n","                if not type(test_data) == list:\n","                    img = image.imread(os.path.join(arg.data_path, \"%d\" % test_data.age[i], \"%d\" % test_data.gender[i],\n","                                                    test_data.filename[i]))\n","                    ax3.imshow(img)\n","                else:\n","                    img = image.imread(test_data[0])\n","                    ax3.imshow(img)\n","            predicted_age.append(vote.argmax() + 18)\n","            plt.show()\n","            print(f\"Age {vote.argmax() + 18}\")\n","    return predicted_age"],"metadata":{"id":"Qpr6Lr-ZwXdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["FACIAL_LANDMARKS_68_IDXS = OrderedDict([\n","    (\"mouth\", (48, 68)),\n","    (\"inner_mouth\", (60, 68)),\n","    (\"right_eyebrow\", (17, 22)),\n","    (\"left_eyebrow\", (22, 27)),\n","    (\"right_eye\", (36, 42)),\n","    (\"left_eye\", (42, 48)),\n","    (\"nose\", (27, 36)),\n","    (\"jaw\", (0, 17))\n","])\n","\n","# For dlibâ€™s 5-point facial landmark detector:\n","FACIAL_LANDMARKS_5_IDXS = OrderedDict([\n","    (\"right_eye\", (2, 3)),\n","    (\"left_eye\", (0, 1)),\n","    (\"nose\", (4))\n","])\n","\n","\n","def shape_to_np(shape, dtype=\"int\"):\n","    coords = np.zeros((shape.num_parts, 2), dtype=dtype)\n","\n","    for i in range(0, shape.num_parts):\n","        coords[i] = (shape.part(i).x, shape.part(i).y)\n","\n","    return coords\n","\n","\n","class FaceAligner:\n","    def __init__(self, predictor, desiredLeftEye=(0.35, 0.35),\n","                 desiredFaceWidth=256, desiredFaceHeight=None):\n","        # store the facial landmark predictor, desired output left\n","        # eye position, and desired output face width + height\n","        self.predictor = predictor\n","        self.desiredLeftEye = desiredLeftEye\n","        self.desiredFaceWidth = desiredFaceWidth\n","        self.desiredFaceHeight = desiredFaceHeight\n","\n","        # if the desired face height is None, set it to be the\n","        # desired face width (normal behavior)\n","        if self.desiredFaceHeight is None:\n","            self.desiredFaceHeight = self.desiredFaceWidth\n","\n","    def align(self, image, gray, rect):\n","        # convert the landmark (x, y)-coordinates to a NumPy array\n","        shape = self.predictor(gray, rect)\n","        shape = shape_to_np(shape)\n","\n","        # simple hack ;)\n","        if (len(shape) == 68):\n","            # extract the left and right eye (x, y)-coordinates\n","            (lStart, lEnd) = FACIAL_LANDMARKS_68_IDXS[\"left_eye\"]\n","            (rStart, rEnd) = FACIAL_LANDMARKS_68_IDXS[\"right_eye\"]\n","        else:\n","            (lStart, lEnd) = FACIAL_LANDMARKS_5_IDXS[\"left_eye\"]\n","            (rStart, rEnd) = FACIAL_LANDMARKS_5_IDXS[\"right_eye\"]\n","\n","        leftEyePts = shape[lStart:lEnd]\n","        rightEyePts = shape[rStart:rEnd]\n","\n","        # compute the center of mass for each eye\n","        leftEyeCenter = leftEyePts.mean(axis=0).astype(\"int\")\n","        rightEyeCenter = rightEyePts.mean(axis=0).astype(\"int\")\n","\n","        # compute the angle between the eye centroids\n","        dY = rightEyeCenter[1] - leftEyeCenter[1]\n","        dX = rightEyeCenter[0] - leftEyeCenter[0]\n","        angle = np.degrees(np.arctan2(dY, dX)) - 180\n","\n","        # compute the desired right eye x-coordinate based on the\n","        # desired x-coordinate of the left eye\n","        desiredRightEyeX = 1.0 - self.desiredLeftEye[0]\n","\n","        # determine the scale of the new resulting image by taking\n","        # the ratio of the distance between eyes in the *current*\n","        # image to the ratio of distance between eyes in the\n","        # *desired* image\n","        dist = np.sqrt((dX ** 2) + (dY ** 2))\n","        desiredDist = (desiredRightEyeX - self.desiredLeftEye[0])\n","        desiredDist *= self.desiredFaceWidth\n","        scale = desiredDist / dist\n","\n","        # compute center (x, y)-coordinates (i.e., the median point)\n","        # between the two eyes in the input image\n","        eyesCenter = (int((leftEyeCenter[0] + rightEyeCenter[0]) // 2),\n","                      int((leftEyeCenter[1] + rightEyeCenter[1]) // 2))\n","\n","        # grab the rotation matrix for rotating and scaling the face\n","        M = cv2.getRotationMatrix2D(eyesCenter, angle, scale)\n","\n","        # update the translation component of the matrix\n","        tX = self.desiredFaceWidth * 0.5\n","        tY = self.desiredFaceHeight * self.desiredLeftEye[1]\n","        M[0, 2] += (tX - eyesCenter[0])\n","        M[1, 2] += (tY - eyesCenter[1])\n","\n","        # apply the affine transformation\n","        (w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n","        output = cv2.warpAffine(image, M, (w, h),\n","                                flags=cv2.INTER_CUBIC)\n","\n","        # return the aligned face\n","        return output\n","\n","\n","def preprocess(test_data):\n","    detector = dlib.get_frontal_face_detector()\n","    predictor = dlib.shape_predictor('/content/gdrive/MyDrive/2024_MCL_Internship/AgeEstimation/datasets/shape_predictor_68_face_landmarks.dat')\n","    fa = FaceAligner(predictor, desiredFaceWidth=224, desiredFaceHeight=224)\n","\n","    aligned_data = []\n","    for f in test_data:\n","        image = cv2.imread(f)\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        rects = detector(gray, 2)\n","        processed = False\n","\n","        for rect in rects:\n","            image = fa.align(image, gray, rect)\n","            processed = True\n","\n","        if not processed:\n","            image = cv2.resize(image, (224, 224))\n","\n","        cv2.imwrite(f.split(\".\")[0] + \"_aligned\" + \".png\", image)\n","        aligned_data.append(f.split(\".\")[0] + \"_aligned\" + \".png\")\n","\n","    return aligned_data"],"metadata":{"id":"hIoTMGGJwd3U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = [\"/content/gdrive/MyDrive/2024_MCL_Internship/AgeEstimation/face.jpg\"]\n","predict_age_random(train_arg, test_data, 41)"],"metadata":{"id":"ymDYT1vQwe_f"},"execution_count":null,"outputs":[]}]}